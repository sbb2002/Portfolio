{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch_ch2_linear_reg.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNOR0lkpfjUu8/vjAGTckAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sbb2002/Portfolio/blob/main/.study/PyTorch/PyTorch_ch2_linear_reg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5evMa8HtSpmB"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7KTfND1TOeP",
        "outputId": "e836431e-dba1-418d-8ff5-289a4ec393cc"
      },
      "source": [
        "# For reproducibility\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f3555631950>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_sLidP0eZzW"
      },
      "source": [
        "|x|y|\n",
        "|-|-|\n",
        "|1|2|\n",
        "|2|4|\n",
        "|3|6|\n",
        "\n",
        "이것을 예시로 x_train으로 사용해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WjxKVMoaoq2"
      },
      "source": [
        "# General hypo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65PVFzamTVO_",
        "outputId": "2908c861-15c2-4e09-e28c-78b46a319163"
      },
      "source": [
        "# Dataset\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "\n",
        "# Model initialize\n",
        "W = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.SGD([W, b], lr=0.01)\n",
        "\n",
        "# Run\n",
        "nb_epochs = 1000\n",
        "for epoch in range(1, nb_epochs + 1):\n",
        "  hypothesis = x_train * W + b\n",
        "  # hypothesis = x_train.matmul(W) + b  # or .mm or @\n",
        "  '''\n",
        "  matmul()을 이용하면...\n",
        "  1. 더 간결하고\n",
        "  2. x의 길이가 바뀌어도 코드를 바꿀 필요가 없고\n",
        "  3. 속도도 더 빠르다!\n",
        "  '''\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "  \n",
        "  # cost로 H(x) 개선. (Always use this code.)\n",
        "  optimizer.zero_grad()   # grad. 초기화\n",
        "  cost.backward()         # grad. 계산\n",
        "  optimizer.step()        # 개선\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch: {:4d}/{} \\: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(epoch, nb_epochs, W.item(), b.item(), cost.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  100/1000 \\: 1.745, b: 0.579 Cost: 0.048403\n",
            "Epoch:  200/1000 \\: 1.800, b: 0.456 Cost: 0.029910\n",
            "Epoch:  300/1000 \\: 1.842, b: 0.358 Cost: 0.018483\n",
            "Epoch:  400/1000 \\: 1.876, b: 0.281 Cost: 0.011421\n",
            "Epoch:  500/1000 \\: 1.903, b: 0.221 Cost: 0.007058\n",
            "Epoch:  600/1000 \\: 1.923, b: 0.174 Cost: 0.004361\n",
            "Epoch:  700/1000 \\: 1.940, b: 0.137 Cost: 0.002695\n",
            "Epoch:  800/1000 \\: 1.953, b: 0.107 Cost: 0.001665\n",
            "Epoch:  900/1000 \\: 1.963, b: 0.084 Cost: 0.001029\n",
            "Epoch: 1000/1000 \\: 1.971, b: 0.066 Cost: 0.000636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXB9BltqguWT"
      },
      "source": [
        "prediction = W * x_train + b\n",
        "prediction = list(prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "id": "V6QSnHacfza9",
        "outputId": "76513e22-82a8-40ca-c9a9-d39493be2ec4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(x_train, y_train, marker='o', linestyle='--')    # x-y graph 1개 추가, 'o'(점 표시), '--'(점선)\n",
        "plt.plot(x_train, prediction, marker='*') # x-y graph 1개 추가, '8'(별 표시)\n",
        "plt.xlabel('x_train')\n",
        "plt.ylabel('y')\n",
        "plt.legend(['y_train', 'prediction'])\n",
        "plt.show()\n",
        "\n",
        "print('당연하게도 이 쉬운 예시용 데이터는 기울기(W)는 2, y절편(b)은 0입니다.\\n \\\n",
        "모델은 완전하게 W와 b를 맞추지는 못하지만 아주 근사한 값을 얻어냅니다. \\\n",
        "epoch가 많을 수록 더 정확해집니다.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "당연하게도 이 쉬운 예시용 데이터는 기울기(W)는 2, y절편(b)은 0입니다.\n",
            " 모델은 완전하게 W와 b를 맞추지는 못하지만 아주 근사한 값을 얻어냅니다. epoch가 많을 수록 더 정확해집니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sO48Dd5jft-M"
      },
      "source": [
        "## Hi-lv. implementation w/ nn.Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq4rNF0Va4Ds"
      },
      "source": [
        "위의 방식은 정론적인 방법이다. 한마디로 Low-lv. implementation이다. 이번에는 pytorch 내에 있는 기능을 이용해서 Hi-lv. implementation해보자. 여기서는 hypothesis를 따로 정의하지 않는다.\n",
        "\n",
        "class를 이용해 nn.Module을 inherit(상속)해서 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPyDRHCxbEoO"
      },
      "source": [
        "class LinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(1, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Guq1sZOpaOzY",
        "outputId": "33b83686-b06c-4230-ba5a-889d5b7c0933"
      },
      "source": [
        "# Dataset\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])\n",
        "\n",
        "# Model initialize\n",
        "model = LinearRegressionModel()\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "# Run\n",
        "nb_epochs = 1000\n",
        "for epoch in range(1, nb_epochs + 1):\n",
        "  prediction = model(x_train)\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "  \n",
        "  # cost로 H(x) 개선. (Always use this code.)\n",
        "  optimizer.zero_grad()   # grad. 초기화\n",
        "  cost.backward()         # grad. 계산\n",
        "  optimizer.step()        # 개선\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    params = list(model.parameters())\n",
        "    W = params[0].item()\n",
        "    b = params[1].item()\n",
        "    print('Epoch: {:4d}/{} \\: {:.3f}, b: {:.3f} Cost: {:.6f}'.format(epoch, nb_epochs, W, b, cost.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  100/1000 \\: 1.584, b: 0.945 Cost: 0.128669\n",
            "Epoch:  200/1000 \\: 1.673, b: 0.743 Cost: 0.079509\n",
            "Epoch:  300/1000 \\: 1.743, b: 0.584 Cost: 0.049132\n",
            "Epoch:  400/1000 \\: 1.798, b: 0.459 Cost: 0.030361\n",
            "Epoch:  500/1000 \\: 1.841, b: 0.361 Cost: 0.018761\n",
            "Epoch:  600/1000 \\: 1.875, b: 0.284 Cost: 0.011593\n",
            "Epoch:  700/1000 \\: 1.902, b: 0.223 Cost: 0.007164\n",
            "Epoch:  800/1000 \\: 1.923, b: 0.175 Cost: 0.004427\n",
            "Epoch:  900/1000 \\: 1.939, b: 0.138 Cost: 0.002736\n",
            "Epoch: 1000/1000 \\: 1.952, b: 0.108 Cost: 0.001690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITtRYru0eRpP"
      },
      "source": [
        "# Multivariable linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUWKdo9Encz0"
      },
      "source": [
        "|국어($x_1$)|영어($x_2$)|수학($x_3$)|표준 총점($y$)|\n",
        "|-|-|-|-|\n",
        "|73|80|75|152|\n",
        "|93|88|93|185|\n",
        "|-|-|-|-|\n",
        "|-|-|-|-|\n",
        "\n",
        "변수가 3개가 있는 입력데이터, 국영수 표준점수 성적표가 있다. 이것으로 W와 b를 얻어보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOticpp_cX7U"
      },
      "source": [
        "# 데이터\n",
        "x1_train = torch.FloatTensor([[73], [93], [89], [96], [73]])\n",
        "x2_train = torch.FloatTensor([[80], [88], [91], [98], [66]])\n",
        "x3_train = torch.FloatTensor([[75], [93], [90], [100], [70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrSwMg99wTuE"
      },
      "source": [
        "## Naive data representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yjfDAvCoQcS",
        "outputId": "cc8b6c84-7017-4ca2-cdc8-cf3330ac5e81"
      },
      "source": [
        "# model initialize\n",
        "w1 = torch.zeros(1, requires_grad=True)\n",
        "w2 = torch.zeros(1, requires_grad=True)\n",
        "w3 = torch.zeros(1, requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "# set the optimizer\n",
        "optimizer = optim.SGD([w1, w2, w3, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  hypothesis = x1_train * w1 + x2_train * w2 + x3_train * w3 + b\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print('Epoch: {:4d}/{} w1: {:.3f} w2: {:.3f} w3: {:.3f} b: {:.3f} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, w1.item(), w2.item(), w3.item(), b.item(), cost.item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:    0/1000 w1: 0.294 w2: 0.294 w3: 0.297 b: 0.003 Cost: 29661.800781\n",
            "Epoch:  100/1000 w1: 0.674 w2: 0.661 w3: 0.676 b: 0.008 Cost: 1.563628\n",
            "Epoch:  200/1000 w1: 0.679 w2: 0.655 w3: 0.677 b: 0.008 Cost: 1.497595\n",
            "Epoch:  300/1000 w1: 0.684 w2: 0.649 w3: 0.677 b: 0.008 Cost: 1.435044\n",
            "Epoch:  400/1000 w1: 0.689 w2: 0.643 w3: 0.678 b: 0.008 Cost: 1.375726\n",
            "Epoch:  500/1000 w1: 0.694 w2: 0.638 w3: 0.678 b: 0.009 Cost: 1.319507\n",
            "Epoch:  600/1000 w1: 0.699 w2: 0.633 w3: 0.679 b: 0.009 Cost: 1.266222\n",
            "Epoch:  700/1000 w1: 0.704 w2: 0.627 w3: 0.679 b: 0.009 Cost: 1.215703\n",
            "Epoch:  800/1000 w1: 0.709 w2: 0.622 w3: 0.679 b: 0.009 Cost: 1.167810\n",
            "Epoch:  900/1000 w1: 0.713 w2: 0.617 w3: 0.680 b: 0.009 Cost: 1.122429\n",
            "Epoch: 1000/1000 w1: 0.718 w2: 0.613 w3: 0.680 b: 0.009 Cost: 1.079390\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTxFpvIDwW_n"
      },
      "source": [
        "## Matrix data representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwx5qyF4pUqQ",
        "outputId": "7cb952be-298c-4447-a1bf-3b3108baced7"
      },
      "source": [
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])\n",
        "\n",
        "# model initialize\n",
        "W = torch.zeros((3, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "# set opt\n",
        "optimizer = optim.SGD([W, b], lr=1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  hypothesis = x_train.matmul(W) + b  # or .mm or @\n",
        "  cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print('Epoch: {:4d}/{} Hypothesis: {} Cost: {:.6f}'.format(\n",
        "      epoch, nb_epochs, hypothesis.squeeze().detach(), cost.item()\n",
        "  ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:    0/20 Hypothesis: tensor([0., 0., 0., 0., 0.]) Cost: 29661.800781\n",
            "Epoch:    1/20 Hypothesis: tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]) Cost: 9298.520508\n",
            "Epoch:    2/20 Hypothesis: tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]) Cost: 2915.712402\n",
            "Epoch:    3/20 Hypothesis: tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]) Cost: 915.040527\n",
            "Epoch:    4/20 Hypothesis: tensor([137.7967, 165.6247, 163.1911, 177.7112, 126.3307]) Cost: 287.936096\n",
            "Epoch:    5/20 Hypothesis: tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]) Cost: 91.371063\n",
            "Epoch:    6/20 Hypothesis: tensor([148.1035, 178.0143, 175.3980, 191.0042, 135.7812]) Cost: 29.758249\n",
            "Epoch:    7/20 Hypothesis: tensor([150.1744, 180.5042, 177.8509, 193.6753, 137.6805]) Cost: 10.445267\n",
            "Epoch:    8/20 Hypothesis: tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]) Cost: 4.391237\n",
            "Epoch:    9/20 Hypothesis: tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]) Cost: 2.493121\n",
            "Epoch:   10/20 Hypothesis: tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]) Cost: 1.897688\n",
            "Epoch:   11/20 Hypothesis: tensor([152.5485, 183.3609, 180.6640, 196.7389, 139.8602]) Cost: 1.710552\n",
            "Epoch:   12/20 Hypothesis: tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]) Cost: 1.651416\n",
            "Epoch:   13/20 Hypothesis: tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]) Cost: 1.632369\n",
            "Epoch:   14/20 Hypothesis: tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]) Cost: 1.625924\n",
            "Epoch:   15/20 Hypothesis: tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]) Cost: 1.623420\n",
            "Epoch:   16/20 Hypothesis: tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]) Cost: 1.622152\n",
            "Epoch:   17/20 Hypothesis: tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]) Cost: 1.621262\n",
            "Epoch:   18/20 Hypothesis: tensor([152.7999, 183.6688, 180.9644, 197.0661, 140.0963]) Cost: 1.620501\n",
            "Epoch:   19/20 Hypothesis: tensor([152.8014, 183.6715, 180.9665, 197.0686, 140.0985]) Cost: 1.619757\n",
            "Epoch:   20/20 Hypothesis: tensor([152.8020, 183.6731, 180.9677, 197.0699, 140.0999]) Cost: 1.619046\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOAq7AcsycPX"
      },
      "source": [
        "## Hi-lv. implementation w/ nn.Module"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kw6YrFl1_FC"
      },
      "source": [
        "이제 눈치챘겠지만, Hi-lv에서는 W, b에 대해 정의할 필요가 없어지고, cost는 torch.nn.Functional을 이용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eg8pmpY2wfSy"
      },
      "source": [
        "class MultivariateLinearRegressionmodel(nn.Module):   # nn.Module에서 상속받음.\n",
        "  def __init__(self):\n",
        "    super().__init__()    # 부모에게 물려받은 것을 자식에서 사용하려면 무조건 super()를 사용해야함.\n",
        "    ''' \n",
        "    왜냐하면 부모의 __init__()이 자식의 __init__에 덮어쓰기(over_writing)되기 때문이다.\n",
        "    이를 방지하려면 super().__init__()을 통해 부모의 __init__()을 쓸 수 있게 된다.\n",
        "    '''\n",
        "    self.linear = nn.Linear(3, 1)   # 입력차원 3, 출력차원 1\n",
        "\n",
        "  def forward(self, x):   # hypothesis 계산을 해준다. gradient는 밑에 backward()에서 해준다.\n",
        "    return self.linear(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPo_kHtV0UnX",
        "outputId": "dbc5c669-bc5b-425e-bc38-f624c82f0c06"
      },
      "source": [
        "# model initialize\n",
        "model = MultivariateLinearRegressionmodel()\n",
        "\n",
        "# set opt\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "for epoch in range(nb_epochs + 1):\n",
        "  # H(x) calculate\n",
        "  prediction = model(x_train)\n",
        "\n",
        "  # cost calculate\n",
        "  cost = F.mse_loss(prediction, y_train)\n",
        "  # cost = torch.mean((hypothesis - y_train) ** 2)\n",
        "  '''\n",
        "  이 식은 동일하지만 F.mse_loss를 이용하면 다른 형태의 loss와 교체가 쉽고 디버깅하기도 쉽다.\n",
        "  ex. l1_loss, smooth_l1_loss 등...\n",
        "  '''\n",
        "\n",
        "  # enhance H(x) from cost\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  print('Epoch: {:4d}/{} Cost: {:.6f}'.format(\n",
        "      epoch, nb_epochs, cost.item()\n",
        "  ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:    0/20 Cost: 39633.414062\n",
            "Epoch:    1/20 Cost: 12431.271484\n",
            "Epoch:    2/20 Cost: 3904.839111\n",
            "Epoch:    3/20 Cost: 1232.251465\n",
            "Epoch:    4/20 Cost: 394.532959\n",
            "Epoch:    5/20 Cost: 131.948334\n",
            "Epoch:    6/20 Cost: 49.637383\n",
            "Epoch:    7/20 Cost: 23.833122\n",
            "Epoch:    8/20 Cost: 15.740526\n",
            "Epoch:    9/20 Cost: 13.199554\n",
            "Epoch:   10/20 Cost: 12.398767\n",
            "Epoch:   11/20 Cost: 12.143410\n",
            "Epoch:   12/20 Cost: 12.059070\n",
            "Epoch:   13/20 Cost: 12.028246\n",
            "Epoch:   14/20 Cost: 12.014258\n",
            "Epoch:   15/20 Cost: 12.005583\n",
            "Epoch:   16/20 Cost: 11.998546\n",
            "Epoch:   17/20 Cost: 11.992002\n",
            "Epoch:   18/20 Cost: 11.985615\n",
            "Epoch:   19/20 Cost: 11.979303\n",
            "Epoch:   20/20 Cost: 11.972960\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McsPdN6T1HXf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}